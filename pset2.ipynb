{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 2: Sequence Labeling\n",
    "=======================\n",
    "\n",
    "- This problem set focuses on sequence labeling with Hidden Markov Models and Deep Learning models.\n",
    "- The target domain is part-of-speech tagging on English and Norwegian from the Universal Dependencies dataset.\n",
    "\n",
    "You will:\n",
    "- Do some basic preprocessing of the data\n",
    "- Build a naive classifier that tags each word with its most common tag\n",
    "- Implement a `Viterbi` tagger using `Hidden Markov Model` in PyTorch\n",
    "- Build a `Bi-LSTM` deep learning model using PyTorch\n",
    "- Build a `Bi-LSTM_CRF` model using the above components (`Viterbi` and `Bi-LSTM`) \n",
    "- Implement techniques to improve your tagger\n",
    "\n",
    "**ATTENTION**: This is a long assignment. You should **start early** and **thoroughly understand Eisenstein Ch. 7**. We will cover some key concepts in the lectures, but there are always some technical details to be explored by yourself in the textbook and codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. Setup\n",
    "\n",
    "**You can skip the setup section if you have correctly configured the conda environment for Assignment 1 (`mynlpenv`).**\n",
    "\n",
    "You should read [this document](https://docs.google.com/document/d/1iuG6dNRAuhOU7K2ZeLNzIaV1w2InvMGq6VazBzZKFu4/edit?usp=sharing) about computing resources and environments before you start.\n",
    "\n",
    "In order to develop this assignment, you will need [python 3](https://www.python.org/downloads/) (we use 3.8) and the following libraries. Most if not all of these are part of [conda](https://docs.conda.io/en/latest/miniconda.html), so a good starting point would be to install that.\n",
    "\n",
    "- [jupyter](http://jupyter.readthedocs.org/en/latest/install.html)\n",
    "- [numpy](https://numpy.org/)\n",
    "- [matplotlib](http://matplotlib.org/users/installing.html)\n",
    "- [nosetests](https://nose.readthedocs.org/en/latest/)\n",
    "- [pandas](http://pandas.pydata.org/)\n",
    "- [torch](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are developing on the computing resources we provided to you, you should be able to install all of them at once using the `environment.yml` file we gave you. Simply by running\n",
    "```sh\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "If you are working on other devices, it may be possible the packages we contained in the yaml file being not compatible. In that case, manually create your environment and install the packages according to the document mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this assignment\n",
    "\n",
    "- This is a Jupyter notebook. You can execute cell blocks by pressing control-enter.\n",
    "- Most of your coding will be in the python source files in the directory ```mynlplib```.\n",
    "- The directory ```tests``` contains unit tests that will be used to grade your assignment, using ```nosetests```. You should run them as you work on the assignment to see that you're on the right track. You are free to look at their source code, if that helps -- though most of the relevant code is also here in this notebook. Learn more about running unit tests at http://pythontesting.net/framework/nose/nose-introduction/\n",
    "- You may want to add more tests, but that is completely optional. \n",
    "- **To submit this assignment, first read ```submission_guide.md```. In short, you want to add, commit, push, and tag your work in your CSE GitLab repo. Apart from the files you edited in `mynlplib/` and the main Jupyter notebook, you should also submit all the output prediction files (`*.preds`). If you are unsure whether a file should be included or not, ask on Ed.**\n",
    "- We have 81 regular points and 4 possible bonus points for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2880,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Python version\n",
      "python: 3.8.13 (default, Mar 28 2022, 11:38:47) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "print('My Python version')\n",
    "\n",
    "print('python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2882,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nose\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My library versions\n",
      "pandas: 1.4.1\n",
      "numpy: 1.22.3\n",
      "matplotlib: 3.5.1\n",
      "nose: 1.3.7\n",
      "torch: 1.8.2\n"
     ]
    }
   ],
   "source": [
    "print('My library versions')\n",
    "\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('nose: {}'.format(nose.__version__))\n",
    "print('torch: {}'.format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether your libraries are the right version, run:\n",
    "\n",
    "`nosetests tests/test_environment.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# use ! to run shell commands in notebook\n",
    "! nosetests tests/test_environment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2884,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# importing all the necessary files from mynlplib\n",
    "from mynlplib import constants, preproc, most_common, clf_base, evaluation\n",
    "from mynlplib import scorer, tagger_base, naive_bayes, hmm, viterbi, bilstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing\n",
    "The part-of-speech tags are defined on the [universal dependencies website](http://universaldependencies.org/en/pos/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2885,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(constants);\n",
    "## Define the file names\n",
    "TRAIN_FILE = constants.TRAIN_FILE\n",
    "DEV_FILE = constants.DEV_FILE\n",
    "TEST_FILE = constants.TEST_FILE\n",
    "TEST_FILE_HIDDEN = constants.TEST_FILE_UNLABELED\n",
    "NR_TRAIN_FILE = constants.NR_TRAIN_FILE\n",
    "NR_DEV_FILE = constants.NR_DEV_FILE\n",
    "NR_TEST_FILE = constants.NR_TEST_FILE\n",
    "NR_TEST_FILE_HIDDEN = constants.NR_TEST_FILE_UNLABELED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To parse the files above, we provide you the parsing function `conll_seq_generator(...)`. Below is a short demo.\n",
    "- The default value for max_insts is `1000000` indicating the number of instances, and this should be enough for our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "## Demo\n",
    "all_tags = set([])\n",
    "for (words, tags) in preproc.conll_seq_generator(TRAIN_FILE):\n",
    "    #print(words,tags)\n",
    "    for tag in tags:\n",
    "        all_tags.add(tag)\n",
    "all_tags = sorted(all_tags)\n",
    "print (all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1.1**: Counting words per tag. (*4 points*)\n",
    "\n",
    "Implement the function `get_tag_word_counts` in `most_common.py`: The function should calculate the number of occurrences of all words for each tag.\n",
    "\n",
    "- **Input**: filename for data file, to be passed as argument to `preproc.conll_seq_generation`\n",
    "- **Output**: dict of counters, where keys are tags\n",
    "- **Tests**: ```test_most_common.py: test_get_top_noun_tags(),test_get_top_verb_tags()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2887,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(most_common);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN [('Bush', 100), ('US', 81), ('Al', 78)]\n",
      "PUNCT [(',', 1616), ('.', 1588), ('\"', 383)]\n",
      "ADJ [('other', 46), ('many', 41), ('Indian', 35)]\n",
      "NOUN [('people', 53), ('time', 48), ('world', 46)]\n",
      "VERB [('is', 335), ('was', 128), ('have', 110)]\n",
      "DET [('the', 1926), ('a', 650), ('The', 216)]\n",
      "ADP [('of', 887), ('in', 738), ('to', 380)]\n",
      "AUX [('have', 139), ('was', 126), ('has', 124)]\n",
      "PRON [('I', 251), ('it', 208), ('he', 131)]\n",
      "PART [('to', 542), (\"'s\", 218), ('not', 172)]\n",
      "SCONJ [('that', 304), ('if', 56), ('as', 47)]\n",
      "NUM [('one', 52), ('two', 28), ('2001', 17)]\n",
      "ADV [('also', 63), ('now', 54), ('when', 53)]\n",
      "CONJ [('and', 932), ('or', 127), ('but', 88)]\n",
      "X [('1', 3), ('2', 3), ('3', 3)]\n",
      "INTJ [('Please', 15), ('please', 3), ('Well', 3)]\n",
      "SYM [('$', 20), ('-', 13), ('/', 7)]\n"
     ]
    }
   ],
   "source": [
    "# this block uses your code to find the three most common words per tag\n",
    "counters = most_common.get_tag_word_counts(TRAIN_FILE)\n",
    "for tag,tag_ctr in counters.items():\n",
    "    print (tag,tag_ctr.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.396s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_most_common.py:test_get_top_verb_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tagging as classification\n",
    "\n",
    "Now you will implement part-of-speech tagging via classification.\n",
    "\n",
    "Tagging quality is evaluated using evalTagger, which takes three arguments:\n",
    "- a tagger, which is a **function** taking a list of words and a tagset as arguments and returns the predicted tags for the words\n",
    "- an output filename\n",
    "- a test file\n",
    "\n",
    "You will want to use lambda expressions to create the first argument for the `eval_tagger(..)` function, as shown below.\n",
    "Here's how it works. We provide a tagger that labels everything as a noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2889,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tagger_base);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1527613022274944\n"
     ]
    }
   ],
   "source": [
    "# here is a tagger that just tags everything as a noun\n",
    "noun_tagger = lambda words, alltags : ['NOUN' for word in words]\n",
    "\n",
    "confusion = tagger_base.eval_tagger(noun_tagger,'nouns.preds',all_tags=all_tags)\n",
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.1** Classification-based tagging. (*4 points*)\n",
    "\n",
    "Now do the same thing as above, but building your tagger *as a classifier.* To do this, implement `make_classifier_tagger()` in `tagger_base.py`. \n",
    "\n",
    "- **Input**: defaultdict of weights\n",
    "- **Output**: return a function that takes in (list of word tokens, list of all possible tags) $\\rightarrow$ tags for each word\n",
    "\n",
    "The function that you output should create the base-features for each token (**use the OFFSET and the TOKEN itself as base-features**)  and then use your `clf_base.predict()` function from Assignment 1. You are free to edit the `clf_base.predict()` function if you don't think you got it right in Assignment 1.\n",
    "- **Tests**: ```test_classifier_tagger.py:test_classifier()```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2891,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tagger_base);\n",
    "reload(clf_base);\n",
    "from mynlplib.constants import OFFSET # OFFSET token is for each tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now create a tagger with weights that predict every token to be a NOUN. \n",
    "The function `get_noun_weights` is already implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2892,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_noun_tagger = tagger_base.make_classifier_tagger(most_common.get_noun_weights())\n",
    "#class_tagger = lambda words,alltags : classifier_noun_tagger(words,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1527613022274944\n"
     ]
    }
   ],
   "source": [
    "confusion = tagger_base.eval_tagger(classifier_noun_tagger,'all-nouns.preds',all_tags=all_tags)\n",
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.550s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!nosetests  tests/test_classifier_tagger.py:test_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2.2** Tagging words by their most common tag. (*4 points*)\n",
    "\n",
    "Now build a classifier tagger that tags each word with its most common tag in the training set. To do this, implement `get_most_common_word_weights` in `most_common.py`.  \n",
    "\n",
    "- **Input**: training file\n",
    "\n",
    "- **Output**: defaultdict of weights\n",
    "\n",
    "This function should return a set weights such that each word should get the tag that is most frequently associated with it in the training data. If the word does not appear in the training data, the weights should be set so that the tagger outputs the **most common tag** in the training data. For the out of vocabulary words, you need to think on how to set the weights so that you tag them by the most common tag.\n",
    "\n",
    "- **Tests**: ```test_classifier.py:test_mcc_tagger_output(), test_mcc_tagger_accuracy()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2894,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(most_common);\n",
    "reload(tagger_base);\n",
    "theta_mc = most_common.get_most_common_word_weights(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2895,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_mc = tagger_base.make_classifier_tagger(theta_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'AUX', 'AUX', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "tags = tagger_mc(['They','can','can','fish'],all_tags)\n",
    "print (tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'ADJ', 'NOUN', 'DET', 'PROPN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "tags = tagger_mc(['The','old','man','the','boat','.'],all_tags)\n",
    "print (tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's run your tagger on the dev data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8111242915513378\n"
     ]
    }
   ],
   "source": [
    "confusion = tagger_base.eval_tagger(tagger_mc,'most-common.preds',all_tags=all_tags)\n",
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 20.831s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_classifier.py:test_mcc_tagger_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes as a tagger.\n",
    "    \n",
    "- You can use your Naive Bayes classifier from Assignment 1 to set the weights for the classifier tagger. We have added in a helper function `naive_bayes.get_nb_weights(..)`. Make sure to retain this function, when you copy your code.\n",
    "- If you don't think you got it right in Assignment 1, you are free to change it now. If you got it right, then just examine the performance of naive bayes as tagger in the following blocks. There is no test or deliverable for this part.\n",
    "- Note that, for text classification, we had a bag of words feature vector and label for each document. For POS tagging, in order to estimate the weights for the classifier tagger, we will consider each token to be its own document. The following helper code converts the dataset to token level bag-of-words feature vector and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2899,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(naive_bayes);\n",
    "nb_weights = naive_bayes.get_nb_weights(TRAIN_FILE, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This gives weights for each tag-word pair that represent $\\log P(word \\mid tag)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2900,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining vocab of words\n",
    "vocab = set([word for tag,word in nb_weights.keys() if word is not constants.OFFSET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6912\n"
     ]
    }
   ],
   "source": [
    "print (len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999045\n",
      "1.0000000000000715\n",
      "0.9999999999998673\n"
     ]
    }
   ],
   "source": [
    "print (sum(np.exp(nb_weights[('ADJ',word)]) for word in vocab))\n",
    "print (sum(np.exp(nb_weights[('NOUN',word)]) for word in vocab))\n",
    "print (sum(np.exp(nb_weights[('PUNCT',word)]) for word in vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have zero weights for OOV (out-of-vocabulary) terms -- think about how this affects the classification here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2903,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print (nb_weights[('ADJ','baaaaaaaaad')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2904,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1314729713701412\n",
      "-3.0977985544826994\n",
      "-2.8092821056787987\n"
     ]
    }
   ],
   "source": [
    "print (nb_weights[('VERB',constants.OFFSET)])\n",
    "print (nb_weights[('ADV',constants.OFFSET)])\n",
    "print (nb_weights[('PRON',constants.OFFSET)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Offsets should correspond to log-probabilities $\\log P(y)$ such that $\\sum_y P(y) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2905,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 2905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.exp(nb_weights[(tag,constants.OFFSET)]) for tag in all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let us look at the accuracy of our naive_bayes tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8091472255173323\n"
     ]
    }
   ],
   "source": [
    "confusion = tagger_base.eval_tagger(tagger_base.make_classifier_tagger(nb_weights),'nb-simple.preds')\n",
    "dev_acc = scorer.accuracy(confusion)\n",
    "print (dev_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just as good as the heuristic tagger from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Viterbi Algorithm\n",
    "\n",
    "In this section you will implement the Viterbi algorithm in **PyTorch**. To get warmed up, let's work out an example by hand. For simplicity, there are only two tags, **N**OUN and **V**ERB. Here are the parameters:\n",
    "\n",
    "| | Value |\n",
    "| ------------- |:-------------:|\n",
    "| $\\log P_E(\\cdot|N)$ | they: -1, can: -3, fish: -3 |\n",
    "| $\\log P_E(\\cdot|V)$ | they: -11, can: -2, fish: -4 |\n",
    "| $\\log P_T(\\cdot|N)$ | N: -5, V: -2, END: -2 |\n",
    "| $\\log P_T(\\cdot|V)$ | N: -1, V: -3, END: -3 |\n",
    "| $\\log P_T(\\cdot|\\text{START})$ | N :-1, V :-2 |\n",
    "\n",
    "where $P_E(\\cdot|\\cdot)$ is the emission probability and $P_T(\\cdot|\\cdot)$ is the transition probability.\n",
    " \n",
    "- In Eisenstein Ch. 7, Figure 7.1 and Table 7.1, we discussed the sentence *They can fish*.\n",
    "- Now work out a more complicated example: \"*They can can fish*\", where the second \"*can*\" refers to the verb of putting things into cans.\n",
    "\n",
    "**Deliverable 3.1** Work out the trellis by hand, and fill in the table. Copy a screenshot of the table to your writeup. (*2 points*)\n",
    "\n",
    "|      | they | can | can | fish | END |\n",
    "|------|------|-----|-----|------|-----|\n",
    "| Start|  n/a | n/a | n/a | n/a  | n/a |\n",
    "| Noun | -2   |     |     |      | n/a |\n",
    "| Verb | -13  |     |     |      | n/a |\n",
    "| End  | n/a  | n/a | n/a | n/a  | -17 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Viterbi ##\n",
    "\n",
    "Here are some predefined weights, corresponding to the weights from the problem 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2906,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = constants.START_TAG\n",
    "END_TAG = constants.END_TAG\n",
    "UNK = constants.UNK\n",
    "\n",
    "nb_weights={('NOUN','they'):-1,\\\n",
    "            ('NOUN','can'):-3,\\\n",
    "            ('NOUN','fish'):-3,\\\n",
    "            ('VERB','they'):-11,\\\n",
    "            ('VERB','can'):-2,\\\n",
    "            ('VERB','fish'):-4,}\n",
    "hmm_trans_weights={('NOUN','NOUN'):-5,\\\n",
    "                   ('VERB','NOUN'):-2,\\\n",
    "                   (END_TAG,'NOUN'):-2,\\\n",
    "                   ('NOUN','VERB'):-1,\\\n",
    "                   ('VERB','VERB'):-3,\\\n",
    "                   (END_TAG,'VERB'):-3,\\\n",
    "                   ('NOUN',START_TAG):-1,\\\n",
    "                   ('VERB',START_TAG):-2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.2** Complete the ```hmm.compute_weights_variables(...)``` function in `hmm.py` file (*4 points*)\n",
    "\n",
    "The function should basically convert the weights to respective pytorch variables.\n",
    "\n",
    "- **Inputs** :\n",
    "    - `nb_weights` (emission weights): dictionary of weights\n",
    "    - `hmm_trans_weights` (transition weights): dictionary of weights\n",
    "    - `vocab`: list of all the words\n",
    "    - `word_to_ix`: a dictionary that maps each word in the vocab to a unique index. **Does not have the OFFSET token.**\n",
    "    - `tag_to_ix`: a dictionary that maps each tag (including the `START_TAG` and the `END_TAG`) to a unique index.  \n",
    "\n",
    "- **Outputs** : returns two torch Variables\n",
    "    - `emission_probs`: torch Variable of a matrix of size `Vocab x Tagset_size`: \n",
    "        such that for a specific weight say `(word1, tag1):value` would result in\n",
    "        `emission_probs[word_to_ix[word1]][tag_to_ix[tag1]]=value`, else a zero. Also, make sure to set weights such that `START_TAG` and `END_TAG` cannot generate any word. **Make sure to ignore the OFFSET weights that might be present in the nb_weights. Consider the words only in your word_to_ix.**\n",
    "        \n",
    "    - `tag_transition_probs`: torch Variable of a matrix of size `Tagset_size x Tagset_size`: \n",
    "        such that for a specific feature say `(tag1, tag2):value` \n",
    "        where tag1 is my succeeding (next) tag, tag2 is my current tag. \n",
    "        This would result in `tag_transition_probs[tag_to_ix[tag1]][tag_to_ix[tag2]]=value`. \n",
    "        Also ensure to set the other weights such that there are no illegal transitions \n",
    "        (like from some tag to START_TAG -or- from END_TAG to some other tag)  \n",
    "\n",
    "- **Tests**: ```test_viterbi.py: test_compute_hmm_weights_variables()```\n",
    "\n",
    "Hint: Use `-np.inf` as weights for illegal transitions (log of a near zero probability). Also, though we call the variables `probs`, at this stage they are more like weights than (log) probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below, observe that we are calculating `tag_to_ix, ix_to_tag, word_to_ix`. These are useful to access a particular emission score for a particular token and a tag. Look through the variables: tag_transition_probs and emission_probs below and it should be clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2907,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(hmm);\n",
    "word_to_ix={'they':0, 'can':1, 'fish':2, UNK:3}\n",
    "tag_to_ix = {START_TAG:0, 'NOUN':1, 'VERB':2, END_TAG:3}\n",
    "ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "all_tags = [START_TAG, 'NOUN', 'VERB', END_TAG]\n",
    "words = ['they', 'can', 'fish']\n",
    "vocab = ['they','can','fish', UNK]\n",
    "# note that we are also including an UNK token: this will be helpful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2908,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_probs, tag_transition_probs = hmm.compute_weights_variables(nb_weights, hmm_trans_weights, vocab, \n",
    "                                                                     word_to_ix, tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2909,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-inf, -inf, -inf, -inf],\n",
      "        [-1., -5., -1., -inf],\n",
      "        [-2., -2., -3., -inf],\n",
      "        [-inf, -2., -3., -inf]])\n"
     ]
    }
   ],
   "source": [
    "print (tag_transition_probs)\n",
    "# tag_transition_probs[0] corresponds to scores for START_TAG from START_TAG, NOUN, VERB, END_TAG\n",
    "# tag_transition_probs[1] corresponds to scores for NOUN from START_TAG, NOUN, VERB, END_TAG\n",
    "# tag_transition_probs[2] corresponds to scores for VERB from START_TAG, NOUN, VERB, END_TAG\n",
    "# tag_transition_probs[3] corresponds to scores for END_TAG from START_TAG, NOUN, VERB, END_TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2910,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-inf,  -1., -11., -inf],\n",
      "        [-inf,  -3.,  -2., -inf],\n",
      "        [-inf,  -3.,  -4., -inf],\n",
      "        [-inf,   0.,   0., -inf]])\n"
     ]
    }
   ],
   "source": [
    "print (emission_probs)\n",
    "# emission_probs[0] corresponds to scores for the token 'they' for START_TAG, NOUN, VERB, END_TAG\n",
    "# emission_probs[1] corresponds to scores for the token 'can' for START_TAG, NOUN, VERB, END_TAG\n",
    "# emission_probs[2] corresponds to scores for the token 'fish' for START_TAG, NOUN, VERB, END_TAG\n",
    "# emission_probs[2] corresponds to scores for the token 'UNK' for START_TAG, NOUN, VERB, END_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we will be using these emission scores as inputs for each token in the input in the following function: ```viterbi_step()```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.3** The Viterbi recurrence. (*6 points*)\n",
    "\n",
    "Implement `viterbi_step` in `mynlplib/viterbi.py`. This is the method that will compute the best path score and corresponding back pointer for a particular token in the sentence for all possible tags, which you will later call from the main viterbi routine. You will also be using this later for the `Bi-LSTM_CRF` model.\n",
    "\n",
    "### Inputs\n",
    "- `all_tags`: list of all tags: includes both the `START_TAG` and the `END_TAG`\n",
    "- `tag_to_ix`: a dictionary that maps each tag (including the `START_TAG` and the `END_TAG`) to a unique index: this is useful to access the respective tag transition scores from the tag_transition_probs variable.\n",
    "- `cur_tag_scores`: pytorch Variable that contains the local emission score for each tag for the current token in the sentence.\n",
    "    - `cur_tag_scores` size is : `[ len(all_tags) ] `\n",
    "- `transition_scores`: pytorch Variable that contains the `tag_transition_scores`. \n",
    "    - `transition_scores` size is : `[ len(all_tags) x len(all_tags) ]` \n",
    "- `prev_scores`: pytorch Variable that contains the scores for each tag for the previous token in the sentence.\n",
    "    - `prev_scores` size is : `[ 1 x len(all_tags) ] `\n",
    "\n",
    "### Outputs\n",
    "- `viterbivars`: a pytorch Variable that contains the global scores for each tag for the current token in the sentence\n",
    "- `bptrs`: a list of idx that contains the best_previous_tag for each tag for the current token in the sentence\n",
    "\n",
    "### Tests\n",
    "- ```test_viterbi.py: test_viterbi_step_init()```  \n",
    "\n",
    "There are a lot of inputs, but the code itself will not be very complex. Make sure you understand what each input represents before starting to write a solution.\n",
    "\n",
    "**Do not convert the pytorch variables into numpy. You will be using this function in BiLSTM-CRF model later on and you need the computation graph to be intact in order to backpropagate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider the sentence: `'they can can fish'`\n",
    "- Let us observe the viterbi scores at each of the tokens 'they', 'can', 'can', 'fish'.\n",
    "- We will walk through this example and all along: these scores should match with the scores you obtained when you worked it out by hand.\n",
    "- **Please note the dimensions of the tensors below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf]])\n"
     ]
    }
   ],
   "source": [
    "reload(viterbi);\n",
    "initial_vec = np.full((1, len(all_tags)),-np.inf)\n",
    "initial_vec[tag_to_ix[START_TAG]][0] = 0 # setting all the score to START_TAG\n",
    "prev_scores = viterbi.get_torch_variable(initial_vec)\n",
    "# these are the previous scores for each_tag: START_TAG, NOUN, VERB, END_TAG\n",
    "print (prev_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The block above says that the only possible previous tag at $m=1$ is `START_TAG`\n",
    "- Now let us look at the tag scores for the first token 'they'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2912,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--START--', 'NOUN', 'VERB', '--END--']\n"
     ]
    }
   ],
   "source": [
    "# make sure both START_TAG and END_TAG is included in all_tags\n",
    "print (all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Carefully observe all the inputs to the `viterbi_step(..)` function here.\n",
    "    - `all_tags`: is the list of all possible tags here\n",
    "    - `tag_to_ix`: a mapping from tags to unique ids: this is useful to access the respective tag transition scores from the `tag_transition_probs` variable.\n",
    "    - `cur_tag_scores`: observe that from previous section: `emission_probs` indicates the emission scores for each tag for each word they: since we will be tagging the word 'they' right now in our example: we will be using ```emission_probs[0]```: note that '0' is the id for our word 'they'.Thus, we send in `emission_probs[0]` as our cur_tag_scores\n",
    "    - `tag_transition_probs`: tag transition probabilities\n",
    "    - `prev_scores`: prev_scores obtained: we have initially calculated these scores above such that the `START_TAG` has all the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2913,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(viterbi);\n",
    "viterbivars, bptrs = viterbi.viterbi_step(all_tags, tag_to_ix, \n",
    "                                          emission_probs[0], \n",
    "                                          tag_transition_probs,\n",
    "                                          prev_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 2914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bptrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following are the scores obtained for each tag for the word token 'they' and the backpointer refers to that particular previous tag which resulted in that score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:  --START--  score:  -inf  back-pointer-tag:  --START--\n",
      "tag:  NOUN  score:  -2.0  back-pointer-tag:  --START--\n",
      "tag:  VERB  score:  -13.0  back-pointer-tag:  --START--\n",
      "tag:  --END--  score:  -inf  back-pointer-tag:  --START--\n"
     ]
    }
   ],
   "source": [
    "scores = viterbivars\n",
    "for k,v in tag_to_ix.items():\n",
    "    print ('tag: ',k, ' score: ',scores[v].item(), ' back-pointer-tag: ', \n",
    "           ix_to_tag[bptrs[v]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `NOUN` has the highest score for the current tag, and its backpointer is to `START_TAG`\n",
    "- Now, let us look at the scores for the tags for the second token 'can'. Send in `emission_probs[1]` as our `current_tag_scores`, and update `prev_scores` to be the scores obtained for $m=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2916,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_scores = viterbi.get_torch_variable([-np.inf, -2, -13, -np.inf])\n",
    "viterbivars, bptrs = viterbi.viterbi_step(all_tags, tag_to_ix,\n",
    "                                          emission_probs[1],\n",
    "                                          tag_transition_probs,\n",
    "                                          prev_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following are the scores obtained for each tag for the word token 'can' and its respective back_pointer tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:  --START--  score:  -inf  back-pointer-tag:  --START--\n",
      "tag:  NOUN  score:  -10.0  back-pointer-tag:  NOUN\n",
      "tag:  VERB  score:  -6.0  back-pointer-tag:  NOUN\n",
      "tag:  --END--  score:  -inf  back-pointer-tag:  --START--\n"
     ]
    }
   ],
   "source": [
    "scores = viterbivars\n",
    "for k,v in tag_to_ix.items():\n",
    "    print ('tag: ',k, ' score: ',scores[v].item(), ' back-pointer-tag: ',\n",
    "           ix_to_tag[bptrs[(all_tags).index(k)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 2512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bptrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, Below, let us look at the scores for the tags for the third token 'can'. So, now we send in `emission_probs[1]` as our `current_tag_scores` and we update `prev_scores` to be the scores obtained for the previous token 'can'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2918,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_scores = viterbi.get_torch_variable([-np.inf, -10, -6, -4]) \n",
    "viterbivars, bptrs = viterbi.viterbi_step(all_tags, tag_to_ix,\n",
    "                                          emission_probs[1],\n",
    "                                          tag_transition_probs,\n",
    "                                          prev_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2919,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:  --START--  score:  -inf  back-pointer-tag:  --START--\n",
      "tag:  NOUN  score:  -10.0  back-pointer-tag:  VERB\n",
      "tag:  VERB  score:  -11.0  back-pointer-tag:  VERB\n",
      "tag:  --END--  score:  -inf  back-pointer-tag:  --START--\n"
     ]
    }
   ],
   "source": [
    "scores = viterbivars\n",
    "for k,v in tag_to_ix.items():\n",
    "    print ('tag: ',k, ' score: ',scores[v].item(), ' back-pointer-tag: ',\n",
    "           ix_to_tag[bptrs[(all_tags).index(k)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 2, 0]"
      ]
     },
     "execution_count": 2339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bptrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Now, let us look at the scores for the tags for the last token 'fish', So, now we send in `emission_probs[2]` as our `current_tag_scores` and we update `prev_scores` to be the scores obtained above for the previous token 'can'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2920,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_scores = viterbi.get_torch_variable([-np.inf, -10, -11, -np.inf])\n",
    "viterbivars, bptrs = viterbi.viterbi_step(all_tags, tag_to_ix,\n",
    "                                           emission_probs[2],\n",
    "                                           tag_transition_probs,\n",
    "                                           prev_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:  --START--  score:  -inf  back-pointer-tag:  --START--\n",
      "tag:  NOUN  score:  -15.0  back-pointer-tag:  VERB\n",
      "tag:  VERB  score:  -16.0  back-pointer-tag:  NOUN\n",
      "tag:  --END--  score:  -inf  back-pointer-tag:  --START--\n"
     ]
    }
   ],
   "source": [
    "scores = viterbivars\n",
    "for k,v in tag_to_ix.items():\n",
    "    print ('tag: ',k, ' score: ',scores[v].item(), ' back-pointer-tag: ',\n",
    "           ix_to_tag[bptrs[(all_tags).index(k)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1, 0]"
      ]
     },
     "execution_count": 2517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bptrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 3.4** Build the Viterbi trellis. (*6 points*)\n",
    "\n",
    "This function should compute the `best_path` and the `path_score`. This function takes in the `emission_scores` for each particular token in the sentence, the `tag_transitions_weight` and returns the best set of tags for that particular sequence. Use `viterbi_step` to implement `build_trellis` in `viterbi.py` in Pytorch. \n",
    "\n",
    "This function should take:\n",
    "- **Inputs**:\n",
    "    - `all_tags`: a list of all tags: includes START_TAG and END_TAG\n",
    "    - `tag_to_ix`: a dictionary that maps each tag to a unique id.\n",
    "    - `cur_tag_scores`: a list of pytorch Variables where each contains the local emission score for each tag for that particular token in the sentence, len(cur_tag_scores) will be equal to len(words): each pytorch variables size would be equal to len(all_tags) indicating the score for each_tag.\n",
    "    - `transition_scores`: pytorch Variable (a matrix) that contains the tag_transition_scores\n",
    "\n",
    "- **Outputs**:\n",
    "    - `path_score`: the score for the best_path\n",
    "    - `best_path`: the actual best_path, which is the list of tags for each token: exclude the `START_TAG` and `END_TAG` here.   \n",
    "    \n",
    "- **Tests**: ```test_viterbi.py: test_trellis_score(), test_build_trellis()```\n",
    "First, make sure to pass the ```test_trellis_score()``` test and then move on to the ```test_build_trellis()``` test.\n",
    "\n",
    "**Note that for the input cur_tag_scores: we are sending in a list of pytorch variables: one for each token in the sentence to be tagged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2922,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--START--', 'NOUN', 'VERB', '--END--']\n"
     ]
    }
   ],
   "source": [
    "# make sure START_TAG and END_TAG are in all_tags\n",
    "print (all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- consider the same sentence as above: 'they can can fish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'can', 'can', 'fish']\n",
      "{'they': 0, 'can': 1, 'fish': 2, '<UNK>': 3}\n"
     ]
    }
   ],
   "source": [
    "words = 'they can can fish'.split()\n",
    "print (words)\n",
    "print (word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below, we create `cur_tag_scores` using the `emission_probs` for each word in the sentence `'they can can fish'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2924,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing cur_tag_scores for the above sentence 'they can can fish'\n",
    "cur_tag_scores = [emission_probs[0],emission_probs[1],emission_probs[1],emission_probs[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete the code to obtain the correct path_score initially and then use the backpointers to obtain the best_path. \n",
    "- Observe the inputs we are sending in for our example: 'they can can fish'\n",
    "    - `all_tags`: list of all tags including the `START_TAG` and `END_TAG`\n",
    "    - `tag_to_ix`: a mapping from tags to their unique ids\n",
    "    - `cur_tag_scores`: a list of pytorch variables: where each one is the score for each tag for a particular token. We send in these scores for each token in the sentence.\n",
    "    - `tag_transition_probs`: tag transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2925,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(viterbi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2926,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_score, best_path = viterbi.build_trellis(all_tags, \n",
    "                                                  tag_to_ix, \n",
    "                                                  cur_tag_scores, \n",
    "                                                  tag_transition_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2927,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'VERB', 'VERB', 'NOUN']\n",
      "-17.0\n"
     ]
    }
   ],
   "source": [
    "print (best_path)\n",
    "print (path_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'VERB', 'NOUN', 'VERB', 'VERB', 'NOUN'] -25.0\n"
     ]
    }
   ],
   "source": [
    "sentence = ['they','can','can','can','can','fish']\n",
    "cur_tag_scores = [emission_probs[word_to_ix[w]] for w in sentence]\n",
    "\n",
    "path_score, best_path = viterbi.build_trellis(all_tags, \n",
    "                                                  tag_to_ix, \n",
    "                                                  cur_tag_scores, \n",
    "                                                  tag_transition_probs)\n",
    "print (best_path, path_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_viterbi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hidden Markov Model: Estimation\n",
    "\n",
    "You will now implement the estimation for a hidden Markov model. Make sure to check out Eisenstein Ch. 7.4 again.\n",
    "\n",
    "We'll start with the tag transitions.\n",
    "\n",
    "**Deliverable 4.1** (*2 points*) Complete the function `most_common.get_tag_trans_counts()`. This function should get the tag transition counts from the each tag to all possible tags. Don't forget to add the transitions from the `START_TAG` and the transitions from the `END_TAG`.\n",
    "\n",
    "You should use the `preproc.conll_seq_generator()` function.  \n",
    "\n",
    "- **Inputs**: `trainfile`, name of file containing training data\n",
    "- **Outputs**: a dictionary where keys are current tags and values are counters of succeeding tags.\n",
    "- **Tests**: ```test_hmm_trans_counts.py: test_tag_trans_counts()```  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2930,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(most_common);\n",
    "tag_trans_counts = most_common.get_tag_trans_counts(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a dict of counters, where the keys are tags.\n",
    "\n",
    "Each counter is the frequency of tags following a given tag, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 1753, 'ADJ': 866, 'PROPN': 562, 'VERB': 65, 'PUNCT': 61, 'ADV': 59, 'NUM': 55, 'DET': 29, 'ADP': 29, 'PRON': 10, 'AUX': 7, 'X': 7, 'SYM': 2})\n",
      "Counter({'PRON': 422, 'PROPN': 327, 'DET': 284, 'ADV': 172, 'ADP': 142, 'NOUN': 108, 'PUNCT': 80, 'CONJ': 79, 'SCONJ': 75, 'ADJ': 67, 'VERB': 64, 'X': 51, 'NUM': 42, 'AUX': 42, 'INTJ': 31, 'SYM': 9, 'PART': 5})\n"
     ]
    }
   ],
   "source": [
    "print (tag_trans_counts['DET'])\n",
    "print (tag_trans_counts[START_TAG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['--START--', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'DET', 'ADP', 'AUX', 'PRON', 'PART', 'SCONJ', 'NUM', 'ADV', 'CONJ', 'X', 'INTJ', 'SYM'])"
      ]
     },
     "execution_count": 2932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_trans_counts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4.2** Estimate transition log-probabilities for an HMM. (*2 points*)\n",
    "\n",
    "Implement `compute_transition_weights` in `hmm.py`. This function should return a dictionary of weights such that ```weights[(tag2,tag1)]``` = indicates the weights for transitions from `tag1` $\\rightarrow$ `tag2`. These weights will be used later for the Viterbi Tagger.\n",
    "\n",
    "### Inputs\n",
    "- Transition counts (generated from `get_tag_trans_counts`)\n",
    "- Smoothing\n",
    "\n",
    "### Outputs\n",
    "- Defaultdict with weights for transition features, in the form $[(y_m,y_{m-1})]$\n",
    "\n",
    "### Tests\n",
    "```test_hmm_trans.py: test_hmm_trans_weights_sum_to_one(), test_hmm_trans_weights_exact_vals() ```  \n",
    "\n",
    "Hints: \n",
    "\n",
    "- Don't forget to assign smoothed probabilities to transitions which do not appear in the counts. \n",
    "- Do not assign probabilities for transitions to the `START_TAG`, which can only come first. This will also affect your computation of the denominator, since you are not smoothing the probability of transitions to the `START_TAG`.\n",
    "- Don't forget to assign probabilities to transitions to the `END_TAG`; this too will affect your denominator.\n",
    "- As always, probabilities should sum to one (this time conditioned on the previous tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2933,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(hmm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2934,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_trans_weights = hmm.compute_transition_weights(tag_trans_counts,.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 -2.9187717324177376\n",
      "64 -3.4420198761822856\n",
      "65 -3.9875599561055597\n",
      "0 -15.069702504983335\n",
      "1753 -0.6928633410799624\n",
      "0 -inf\n",
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print (tag_trans_counts[START_TAG]['NOUN'], hmm_trans_weights[('NOUN',START_TAG)])\n",
    "print (tag_trans_counts[START_TAG]['VERB'], hmm_trans_weights[('VERB',START_TAG)])\n",
    "print (tag_trans_counts['DET']['VERB'], hmm_trans_weights[('VERB','DET')])\n",
    "print (tag_trans_counts['DET']['INTJ'], hmm_trans_weights[('INTJ','DET')])\n",
    "print (tag_trans_counts['DET']['NOUN'], hmm_trans_weights[('NOUN','DET')])\n",
    "print (tag_trans_counts['VERB'][START_TAG], hmm_trans_weights[(START_TAG,'VERB')])\n",
    "#print (tag_trans_counts[END_TAG]['VERB']) # will throw key error\n",
    "print (hmm_trans_weights[('VERB',END_TAG)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These log-probabilities should normalize to when summing over $y_m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2936,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n",
      "1.0\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# calculating all tags here, we also add END_TAG here.\n",
    "all_tags = sorted(list(tag_trans_counts.keys()) + [END_TAG])\n",
    "print (sum(np.exp(hmm_trans_weights[(tag,'NOUN')]) for tag in all_tags))\n",
    "print (sum(np.exp(hmm_trans_weights[(tag,'SYM')]) for tag in all_tags))\n",
    "print (sum(np.exp(hmm_trans_weights[(tag,'ADJ')]) for tag in all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2937,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.240s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_hmm_trans.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Now let us compute the weight variables for the whole dataset**\n",
    "- So, we recalculate them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2938,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculating nb_weights for the whole dataset\n",
    "nb_weights = naive_bayes.get_nb_weights(TRAIN_FILE, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'--END--': 0, '--START--': 1, 'ADJ': 2, 'ADP': 3, 'ADV': 4, 'AUX': 5, 'CONJ': 6, 'DET': 7, 'INTJ': 8, 'NOUN': 9, 'NUM': 10, 'PART': 11, 'PRON': 12, 'PROPN': 13, 'PUNCT': 14, 'SCONJ': 15, 'SYM': 16, 'VERB': 17, 'X': 18}\n"
     ]
    }
   ],
   "source": [
    "# recalculating tag_to_ix\n",
    "tag_to_ix = {}\n",
    "for tag in list(all_tags):\n",
    "    if tag not in tag_to_ix:\n",
    "        tag_to_ix[tag]=len(tag_to_ix)\n",
    "print (tag_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Note about OOV's**: We provide a helper function to calculate the `vocab` as shown below. We add an `UNK` token to the `vocab`. This is useful because, when we don't find a token's emission weight, we choose the `UNK` tokens weight and proceed with our tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6913\n"
     ]
    }
   ],
   "source": [
    "# recalculating vocab for the whole dataset now. # we also add an UNK token to the vocab here\n",
    "reload(most_common);\n",
    "vocab, word_to_ix = most_common.get_word_to_ix(TRAIN_FILE) # obtains all the words in the file\n",
    "print (len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2941,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_probs, tag_transition_probs = hmm.compute_weights_variables(nb_weights, hmm_trans_weights, \n",
    "                                                                     vocab, word_to_ix, tag_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4.3** (*2 points*)\n",
    "\n",
    "We can now combine `Viterbi` and the `HMM` weights to compute the tag sequence for the example sentence.\n",
    "\n",
    "- **Tests**: ```test_hmm.py: test_hmm_on_example_sentence()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--END--', '--START--', 'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "# make sure all_tags has END_TAG\n",
    "print (all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-32.4458]]), ['PRON', 'AUX', 'AUX', 'NOUN', 'PUNCT'])"
      ]
     },
     "execution_count": 2943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(viterbi);\n",
    "viterbi.build_trellis(all_tags,\n",
    "                      tag_to_ix,\n",
    "                      [emission_probs[word_to_ix[w]] for w in ['they', 'can', 'can', 'fish','.']], \n",
    "                      tag_transition_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 4.4** (*2 points*)\n",
    "\n",
    "- Run your HMM tagger on the dev data and test data, using the code blocks below. Though you cannot run the scorer on the test data, make sure you run the `tagger_base.apply_tagger(...)` cell to generate a test predictions file, on which we can run the scorer.\n",
    "- **Tests**: ```test_hmm.py: test_hmm_dev_accuracy(), test_hmm_test_accuracy()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe that, based on our definition of the viterbi function, we need to send in two sets of important scores to the `build_trellis()` function\n",
    "    - cur_tag_scores: a list of emission scores for each tag for each token in the sentence\n",
    "    - tag_transition_probs: tag transition scores\n",
    "- When using the `HMM` with `Viterbi` Tagger: we have calculated the `cur_tag_scores` using the `naive_bayes_weights` and got the `tag_transition_probs` in 4.2.\n",
    "- As already mentioned above, for `cur_tag_scores`, we are sending in a list of pytorch variables: one for each token in the sentence to be tagged\n",
    "- Below, in the tagger that we create: we first calculate the set of `cur_tag_scores` for the words in the sentence and then send them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2944,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(viterbi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe the way `cur_tag_scores` is computed in the loop below: \n",
    "    - For each particular word in a sentence: we assign the respective emission scores if it is present in our `vocab`, else we assign the emission_scores of an `UNK` token.\n",
    "    - This is repeated everywhere from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From/ADP the/DET AP/NOUN comes/VERB this/DET story/NOUN :/PUNCT \n",
      "\n",
      "President/PROPN Bush/PROPN on/ADP Tuesday/PROPN nominated/PROPN two/NUM individuals/NOUN to/PART replace/VERB retiring/DET jurists/NOUN on/ADP federal/ADJ courts/NOUN in/ADP the/DET Washington/PROPN area/NOUN ./PUNCT \n",
      "\n",
      "Bush/PROPN nominated/PROPN Jennifer/PROPN M./PART Anderson/VERB for/ADP a/DET 15/NUM -/PUNCT year/NOUN term/NOUN as/ADP associate/NOUN judge/NOUN of/ADP the/DET Superior/ADJ Court/NOUN of/ADP the/DET District/PROPN of/ADP Columbia/PROPN ,/PUNCT replacing/PROPN Steffen/PROPN W./PROPN Graae/PROPN ./PUNCT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is just for fun\n",
    "for i,(words,_) in enumerate(preproc.conll_seq_generator(DEV_FILE)):\n",
    "    cur_tag_scores = [emission_probs[word_to_ix[w]] \n",
    "                      if w in word_to_ix else emission_probs[word_to_ix[UNK]] for w in words]\n",
    "    \n",
    "    pred_tags = viterbi.build_trellis(all_tags,\n",
    "                                      tag_to_ix,\n",
    "                                      cur_tag_scores,\n",
    "                                      tag_transition_probs)[1]\n",
    "    for word,pred_tag in zip(words,pred_tags):\n",
    "        print (\"%s/%s\"%(word,pred_tag),end=\" \")\n",
    "    print ('\\n')\n",
    "    if i >= 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2946,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = lambda words, all_tags : viterbi.build_trellis(all_tags, \n",
    "                                                        tag_to_ix,\n",
    "                                                            [emission_probs[word_to_ix[w]] \n",
    "                                                             if w in word_to_ix \n",
    "                                                             else emission_probs[word_to_ix[UNK]] \n",
    "                                                             for w in words],\n",
    "                                                            tag_transition_probs)[1]\n",
    "confusion = tagger_base.eval_tagger(tagger,'hmm-dev-en.preds', all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2947,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841307499670489\n"
     ]
    }
   ],
   "source": [
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is around 3% better than the heuristic tagger and Naive Bayes tagger we implemented initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2948,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_tagger(tagger,'hmm-te-en.preds',all_tags, testfile=TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8402749140893471\n"
     ]
    }
   ],
   "source": [
    "# you don't have en-ud-test.conllu, so you can't run this\n",
    "te_confusion = scorer.get_confusion(TEST_FILE,'hmm-te-en.preds')\n",
    "print (scorer.accuracy(te_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-Speech Tagging in Norwegian\n",
    "**Deliverable 4.5** (*2 points*)\n",
    "- Now, let us do part of speech tagging for data in Norwegian language using the Viterbi Tagger.\n",
    "- **Tests**: ```test_hmm.py: test_nr_hmm_dev_accuracy(), test_nr_hmm_test_accuracy()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we calculate the `nb_weights`/emission weights for the norwegian language in a similar way as we did for the english language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2949,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculating nb_weights for the whole dataset\n",
    "nb_weights_nr = naive_bayes.get_nb_weights(NR_TRAIN_FILE, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we calculate the `tag_transition_weights` for the norwegian language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2950,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_trans_counts_nr = most_common.get_tag_trans_counts(NR_TRAIN_FILE)\n",
    "hmm_trans_weights_nr = hmm.compute_transition_weights(tag_trans_counts_nr,.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we obtain the `vocab`, `word_to_ix` and `tag_to_ix` below for the norwegian language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2951,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'--END--': 0, '--START--': 1, 'ADJ': 2, 'ADP': 3, 'ADV': 4, 'AUX': 5, 'CCONJ': 6, 'DET': 7, 'INTJ': 8, 'NOUN': 9, 'NUM': 10, 'PART': 11, 'PRON': 12, 'PROPN': 13, 'PUNCT': 14, 'SCONJ': 15, 'SYM': 16, 'VERB': 17, 'X': 18}\n"
     ]
    }
   ],
   "source": [
    "# Using helper functions to obtain vocab, word_to_ix, tag_to_ix\n",
    "all_tags_nr = sorted(list(tag_trans_counts_nr.keys()) + [END_TAG])\n",
    "vocab_nr, word_to_ix_nr = most_common.get_word_to_ix(NR_TRAIN_FILE) #obtains all the words in the vocab\n",
    "tag_to_ix_nr={}\n",
    "for tag in list(all_tags_nr):\n",
    "    tag_to_ix_nr[tag]=len(tag_to_ix_nr)\n",
    "print (tag_to_ix_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we convert these weights into pytorch variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2952,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_probs_nr, tag_transition_probs_nr = hmm.compute_weights_variables(nb_weights_nr, hmm_trans_weights_nr, \n",
    "                                                                           vocab_nr, word_to_ix_nr, tag_to_ix_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we construct a viterbi tagger for the norwegian language using these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2953,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = lambda words, all_tags : viterbi.build_trellis(all_tags_nr, \n",
    "                                                           tag_to_ix_nr,\n",
    "                                                            [emission_probs_nr[word_to_ix_nr[w]] \n",
    "                                                             if w in word_to_ix_nr \n",
    "                                                             else emission_probs_nr[word_to_ix_nr[UNK]] \n",
    "                                                             for w in words],\n",
    "                                                            tag_transition_probs_nr)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2954,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = tagger_base.eval_tagger(tagger,'hmm-dev-nr.preds', all_tags_nr,\n",
    "                                    trainfile=NR_TRAIN_FILE,\n",
    "                                    testfile=NR_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861732644865175\n"
     ]
    }
   ],
   "source": [
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..E.E\n",
      "======================================================================\n",
      "ERROR: test_hmm.test_hmm_test_accuracy\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/iws/daksh97/miniconda3/envs/mynlpenv/lib/python3.8/site-packages/nose/case.py\", line 198, in runTest\n",
      "    self.test(*self.arg)\n",
      "  File \"/homes/iws/daksh97/CSE447-sp22-a2-daksh97/tests/test_hmm.py\", line 41, in test_hmm_test_accuracy\n",
      "    confusion = scorer.get_confusion(TEST_FILE,'hmm-te-en.preds')\n",
      "  File \"/homes/iws/daksh97/CSE447-sp22-a2-daksh97/mynlplib/scorer.py\", line 26, in get_confusion\n",
      "    with codecs.open(keyfilename,encoding='utf8') as keyfile:\n",
      "  File \"/homes/iws/daksh97/miniconda3/envs/mynlpenv/lib/python3.8/codecs.py\", line 905, in open\n",
      "    file = builtins.open(filename, mode, buffering)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/en-ud-test.conllu'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_hmm.test_nr_hmm_test_accuracy\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/iws/daksh97/miniconda3/envs/mynlpenv/lib/python3.8/site-packages/nose/case.py\", line 198, in runTest\n",
      "    self.test(*self.arg)\n",
      "  File \"/homes/iws/daksh97/CSE447-sp22-a2-daksh97/tests/test_hmm.py\", line 53, in test_nr_hmm_test_accuracy\n",
      "    confusion = scorer.get_confusion(NR_TEST_FILE,'hmm-te-nr.preds')\n",
      "  File \"/homes/iws/daksh97/CSE447-sp22-a2-daksh97/mynlplib/scorer.py\", line 26, in get_confusion\n",
      "    with codecs.open(keyfilename,encoding='utf8') as keyfile:\n",
      "  File \"/homes/iws/daksh97/miniconda3/envs/mynlpenv/lib/python3.8/codecs.py\", line 905, in open\n",
      "    file = builtins.open(filename, mode, buffering)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/no_bokmaal-ud-test.conllu'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 5.025s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_hmm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2957,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_tagger(tagger,'hmm-te-nr.preds',all_tags_nr, \n",
    "                         trainfile=NR_TRAIN_FILE, testfile=NR_TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8535171347590828\n"
     ]
    }
   ],
   "source": [
    "# you don't have no_bokmaal-ud-test.conllu, so you can't run this\n",
    "te_confusion = scorer.get_confusion(NR_TEST_FILE,'hmm-te-nr.preds')\n",
    "print (scorer.accuracy(te_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. BiLSTM model for Part of Speech Tagging\n",
    "\n",
    "A `BiLSTM` model for part-of-speech tagging takes as input the word embeddings of the tokens in the sentence, and passes them through an `LSTM`. For each token, the hidden state is used as input to a network that computes a score for each tag. A softmax layer then converts these scores to probabilities. This model should be trained end-to-end with the cross-entropy loss function.\n",
    "\n",
    "We will be building this `BiLSTM` model as a class using pytorch. Your implementation will include three functions:\n",
    "\n",
    "- `BiLSTM.__init__()`: define all the necessary model parameters\n",
    "    1. The word-embedding matrix, which maps the words to vectors.\n",
    "    2. A BiLSTM Neural Network, which takes the word embeddings for the words as inputs and produces a hidden state for each token.\n",
    "    3. A one layer feedforward Neural Network, which projects the hidden state to a vector of scores for each tag.\n",
    "- `forward()`: pass the input through the model, obtaining probability distributions over tags\n",
    "    1. Convert all the words to their word-vectors from the word-embedding matrix.\n",
    "    2. Pass these word-vectors through a BiLSTM to obtain hidden states for the tokens.\n",
    "    3. Pass these hidden states through the feedforward neural network to obtain the probability distributions of tags for each token.\n",
    "- `cross_entropy_loss()`: the training objective\n",
    "\n",
    "The description below provides additional help for each of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in the vocabulary:  6900\n",
      "6899\n"
     ]
    }
   ],
   "source": [
    "# recalculating vocab: obtains the most common 6900 words from the file\n",
    "vocab, word_to_ix = most_common.get_word_to_ix(TRAIN_FILE, 6900)\n",
    "print ('words in the vocabulary: ',len(word_to_ix))\n",
    "print (word_to_ix[UNK])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- updating `tag_to_ix` and `all_tags` to remove `START_TAG` and `END_TAG`: these labels are not necessary in tagging with `BiLSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2959,
   "metadata": {},
   "outputs": [],
   "source": [
    "if START_TAG in all_tags:\n",
    "    all_tags.remove(START_TAG)\n",
    "if END_TAG in all_tags:\n",
    "    all_tags.remove(END_TAG)\n",
    "tag_to_ix = {}\n",
    "for tag in all_tags:\n",
    "    if tag not in tag_to_ix:\n",
    "        tag_to_ix[tag] = len(tag_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a look at the helper functions `preproc.load_data(...)` and `bilstm.prepare_sequence(...)` \n",
    "    - `preproc.load_data(...)`: loads the data into a list of lists\n",
    "    - `bilstm.prepare_sequence(...)` given a sequence of words/tags and the `to_ix` dictionary that maps them to its unique indices: it returns a sequence of its unique indices.\n",
    "- The function `prepare_sequence()` will be used a lot from now on to convert the input to a `torch.LongTensor` and then send it to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading Train data for english:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2960,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  17  759   14  114  451   20    0  278    5   33  901 2020    2]\n",
      "[ 5  0  3  3 15  1  5  7  1  5  7  7 12]\n"
     ]
    }
   ],
   "source": [
    "reload(preproc);\n",
    "X_tr, Y_tr = preproc.load_data(TRAIN_FILE)\n",
    "\n",
    "print (bilstm.prepare_sequence(X_tr[5],word_to_ix).data.numpy())\n",
    "print (bilstm.prepare_sequence(Y_tr[5],tag_to_ix).data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading Dev data for english:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2961,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dev data\n",
    "X_dv, Y_dv = preproc.load_data(DEV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading Test data for english:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2962,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test data\n",
    "X_te, Y_te = preproc.load_data(TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.1**: (*4 points*)\n",
    "- Complete the `__init__()` function in the Class `bilstm.BiLSTM` that defines the model parameters:\n",
    "    - **Inputs**:\n",
    "        - `vocab_size`: vocab size of the model\n",
    "        - `tag_to_ix`: tag_to_ix: a dictionary that maps the tags to its unique id\n",
    "        - `embedding_dim`: embedding dimension for the words\n",
    "        - `hidden_dim`: hidden dimension for the `Bi-LSTM` model\n",
    "        - `embeddings`: embedding matrix of size: vocab_size x embedding_dim (this is to initialize embeddings with pretrained embeddings).\n",
    "    - The function does the following:\n",
    "        - Create an embedding matrix using torch.nn.Embedding of the size vocab \n",
    "            - [check this pytorch_doc_for_embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "        - Create a Bi-LSTM model with just one layer, and hidden dimension = hidden_dim \n",
    "            - [check this pytorch_doc_for_LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "        - Also add a FullyConnected Layer, that would project the hidden state onto the tag space. \n",
    "            - [check this pytorch_doc_for_Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "    - Make sure to name the parameters as follows: The unit tests will check for these variables\n",
    "        - `self.word_embeds`\n",
    "        - `self.lstm`\n",
    "        - `self.hidden2tag`\n",
    "    - **Tests**: ```test_bilstm.py: test_dlmodel_init()```\n",
    "    - All you need to do here is to define the model parameters here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below, you can find brief example of how these components are created in Torch. In these examples, the dimensions are arbitrary; you will need to determine the correct dimensions for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this basically defines a matrix of embeddings where the vocab_size=10 and the embedding_dim=10 \n",
    "word_embeds = nn.Embedding(num_embeddings=10, embedding_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following line is how you define an LSTM such that the input_size of the vector=10, \n",
    "# hidden state of each LSTM (forward and backward) =20, num of layers=1, \n",
    "# bidirectional=True indicating both forward and backward LSTM will be included.\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following line is the way to define a Fully Connected Layer with input_dim=40, output_dim=10 and bias=True.\n",
    "hidden2tag = nn.Linear(in_features=40, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once, you have defined the parameters of the model: check if you have done it right using the unit test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2963,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 30\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2964,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (word_embeds): Embedding(6900, 30)\n",
       "  (lstm): LSTM(30, 15, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=30, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.2** (*4 points*)\n",
    "- Complete the `bilstm.BiLSTM.forward()` function in the `bilstm.BiLSTM` class to obtain the scores for each tag for each of the words in a sentence.\n",
    "- **Input**:\n",
    "    - sentence: a sequence of ids for each word in the sentence\n",
    "- The function does the following:\n",
    "    - Obtains the embeddings for the input sequence\n",
    "    - passes them through an `LSTM` to get the respective hidden states; use the hidden state initialized in the function.\n",
    "    - projects them onto the tag-space using the FC layer\n",
    "- Make sure to reshape the embeddings of the words before sending them to the `BiLSTM`. The axes semantics are: `seq_len, mini_batch, embedding_dim`.\n",
    "- You can use the .view() method to reshape a tensor. You might need to use this, as the neural network components expect their inputs to have a certain shape. [check the pytorch doc on view](https://pytorch.org/docs/stable/tensor_view.html)\n",
    "- Later if you happen to run an evaluation cell for the same LSTM model several times, you might see slightly different accuracy result each time. This is because we have randomness in `init_hidden()` of the LSTM module (and thus in `forward()`).\n",
    "- **Tests**: ```test_bilstm.py: test_dlmodel_forward()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2965,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2966,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating your model\n",
    "torch.manual_seed(711);\n",
    "model = bilstm.BiLSTM(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2967,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing your first sentence to be an input\n",
    "words= X_tr[5]\n",
    "tags = Y_tr[5]\n",
    "sentence = bilstm.prepare_sequence(words, word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this calls the `forward()` function on the model, which returns the tag_scores for each tag for each particular token in the sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 17])\n",
      "tensor([ 0.1864,  0.0482, -0.1866,  0.2131,  0.0637], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "lstm_feats = model(sentence)\n",
    "print(lstm_feats.shape)\n",
    "print (lstm_feats[0][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we provide the `predict()` function that returns the set of tags obtained for the specific input by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADJ', 'ADJ', 'PART']\n"
     ]
    }
   ],
   "source": [
    "tags = model.predict(sentence)\n",
    "print (tags[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the model for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.5472518782127324\n",
      "Epoch 3: Dev Accuracy: 0.6588902069329116\n",
      "Epoch 5: Dev Accuracy: 0.6931593515223409\n",
      "Epoch 7: Dev Accuracy: 0.7095030974034533\n",
      "Epoch 9: Dev Accuracy: 0.7315144325820483\n"
     ]
    }
   ],
   "source": [
    "reload(bilstm);\n",
    "torch.manual_seed(711);\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = bilstm.train_model(loss, model, X_tr,Y_tr, word_to_ix, tag_to_ix, \n",
    "                                        X_dv, Y_dv, num_its=10, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.1,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(bilstm);\n",
    "bilstm.plot_results(losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2970,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.926s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_bilstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 5.3**: (*4 points*)\n",
    "- As you can see from above, BiLSTM model performs worse than the Viterbi tagger.\n",
    "- Use pretrained embeddings like the following to improve your performance.\n",
    "- Check the following sources: [fastText](https://github.com/facebookresearch/fastText), [Polyglot](https://polyglot.readthedocs.io/en/latest/Embeddings.html), [word2vec](https://code.google.com/archive/p/word2vec/), [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "- Tune the hyperparameters such that you obtain atleast `85.00%` accuracy on the dev set.\n",
    "- You can try changing the no. of iterations, optimizers, no. of LSTM layers, the hidden dimension units, the FC layer dimensions, or use pretrained word embeddings like word2vec, fastText, polyglot, character features etc..\n",
    "- **Tests**: ```test_bilstm.py: test_bilstm_dev_accuracy()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remember: After training a model once, everytime when you rerun the train_model(...) function, the model is retrained on top of the previous parameters. If you want to start afresh, make sure the model is reinitialized and then trained.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: pretrained embeddings\n",
    "\n",
    "- *Polyglot* provides pre-trained word embeddings for many languages. We already helped you download the English file from [here](https://sites.google.com/site/rmyeid/projects/polyglot) to `/data`.\n",
    "- Use the following helper function to load in the polyglot embeddings, which you can use to initialize your parameter embeddings in your model. You need to make sure your embedding_dim matches your embeddings size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2814,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "filename = 'data/polyglot-en.pkl'\n",
    "word_embeddings = bilstm.obtain_polyglot_embeddings(filename, word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let us have a look at these word embeddings. We can observe the cosine similarity between two word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2815,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(emb1, emb2): # function to return the cosine similarity between the embeddings\n",
    "    return emb1.dot(emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2816,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6901981\n",
      "0.05310622\n",
      "0.08789004\n"
     ]
    }
   ],
   "source": [
    "diremb = word_embeddings[word_to_ix['dire']]\n",
    "catemb = word_embeddings[word_to_ix['catastrophic']]\n",
    "amazemb = word_embeddings[word_to_ix['success']]\n",
    "print(cosine(diremb,catemb)) # dire and catastrophic are similar\n",
    "print(cosine(diremb,amazemb))\n",
    "print(cosine(catemb,amazemb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, all we need to do is send in the word_embeddings when initializing your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(711);\n",
    "embedding_dim = 64\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM(len(word_to_ix), tag_to_ix, embedding_dim, hidden_dim, word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.7266376696981679\n",
      "Epoch 2: Dev Accuracy: 0.7831817582707262\n",
      "Epoch 3: Dev Accuracy: 0.811519704758139\n",
      "Epoch 4: Dev Accuracy: 0.8273362330301832\n",
      "Epoch 5: Dev Accuracy: 0.8357717147752735\n",
      "Epoch 6: Dev Accuracy: 0.8332674311321998\n",
      "Epoch 7: Dev Accuracy: 0.8422301304863582\n",
      "Epoch 8: Dev Accuracy: 0.8506656122314485\n",
      "Epoch 9: Dev Accuracy: 0.8535653090813233\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = bilstm.train_model(loss, model, X_tr,Y_tr, word_to_ix, tag_to_ix, \n",
    "                                        X_dv, Y_dv, num_its=9, status_frequency=1,\n",
    "                                        optim_args = {'lr':0.05,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(bilstm);\n",
    "bilstm.plot_results(losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tagger_base);\n",
    "reload(bilstm);\n",
    "confusion = tagger_base.eval_model(model,'bilstm-dev-en.preds', word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8551469619085278\n"
     ]
    }
   ],
   "source": [
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_model(model,'bilstm-te-en.preds',word_to_ix, all_tags, testfile=TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745979381443299\n"
     ]
    }
   ],
   "source": [
    "# you don't have en-ud-test.conllu, so you can't run this\n",
    "te_confusion = scorer.get_confusion(TEST_FILE,'bilstm-te-en.preds')\n",
    "print (scorer.accuracy(te_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may want to try other ideas like: learning rate, hidden layer sizes, optimizers, other pretrained embeddings for English etc. to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging for Norwegian\n",
    "Make sure your code runs on the Norwegian dataset as well. You may want to use the pretrained embeddings for norwegian to improve the performance of the model. However, there is no deliverable or test for this part.\n",
    "- Run the `BiLSTM` model on the norwegian dataset using the `BiLSTM` tagger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2971,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculating all_tags and tag_to_ix for the norwegian language\n",
    "if START_TAG in all_tags_nr:\n",
    "    all_tags_nr.remove(START_TAG)\n",
    "if END_TAG in all_tags_nr:\n",
    "    all_tags_nr.remove(END_TAG)\n",
    "\n",
    "tag_to_ix_nr = {}\n",
    "for tag in all_tags_nr:\n",
    "    if tag not in tag_to_ix_nr:\n",
    "        tag_to_ix_nr[tag] = len(tag_to_ix_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in the vocabulary:  7600\n",
      "7599\n"
     ]
    }
   ],
   "source": [
    "# recalculating the vocab for the norwegian language: obtains the most common 7600 words from the file\n",
    "vocab_nr, word_to_ix_nr = most_common.get_word_to_ix(NR_TRAIN_FILE, 7600)\n",
    "print ('words in the vocabulary: ',len(word_to_ix_nr))\n",
    "print (word_to_ix_nr[UNK])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading training data for norwegian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2973,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(preproc);\n",
    "X_tr_nr, Y_tr_nr = preproc.load_data(NR_TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading dev data for norwegian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2974,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dv_nr, Y_dv_nr = preproc.load_data(NR_DEV_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading test data for norwegian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2975,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_nr, Y_te_nr = preproc.load_data(NR_TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2976,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the random seed\n",
    "torch.manual_seed(711);\n",
    "\n",
    "# initializing your model\n",
    "embedding_dim = 30\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM(len(word_to_ix_nr), tag_to_ix_nr, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2036,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.627653471026965\n",
      "Epoch 3: Dev Accuracy: 0.7287435456110155\n",
      "Epoch 5: Dev Accuracy: 0.7669535283993115\n",
      "Epoch 7: Dev Accuracy: 0.7835915088927137\n",
      "Epoch 9: Dev Accuracy: 0.802180149168101\n"
     ]
    }
   ],
   "source": [
    "# training your model for norwegian data\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = bilstm.train_model(loss, model, X_tr_nr,Y_tr_nr, word_to_ix_nr, tag_to_ix_nr, \n",
    "                                        X_dv_nr, Y_dv_nr, num_its=10, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.2,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2037,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(bilstm);\n",
    "bilstm.plot_results(losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2038,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tagger_base);\n",
    "reload(bilstm);\n",
    "confusion = tagger_base.eval_model(model,'bilstm-dev-nr.preds', word_to_ix_nr, \n",
    "                                   trainfile=NR_TRAIN_FILE, testfile=NR_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2039,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8059667240390131\n"
     ]
    }
   ],
   "source": [
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2040,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_model(model,'bilstm-te-nr.preds',word_to_ix_nr, all_tags_nr, \n",
    "                        trainfile=NR_TRAIN_FILE, testfile=NR_TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8050760113372842\n"
     ]
    }
   ],
   "source": [
    "# you don't have no_bokmaal-ud-test.conllu, so you can't run this\n",
    "te_confusion = scorer.get_confusion(NR_TEST_FILE,'bilstm-te-nr.preds')\n",
    "print (scorer.accuracy(te_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cuda\n",
    "**Note: cuda is an Nvidia interface/library for accelerating computation on Nvidia GPUs. The usage of cuda is fully optional. Also, debugging in the cuda mode is much more difficult than in the normal cpu mode. First make sure your implementation works, and then convert to cuda if you want.**\n",
    "\n",
    "If you want to run the code on a GPU: \n",
    "- make sure you convert the input and target Tensors to be cuda variables like below:\n",
    "\n",
    "`inputs, labels = inputs.cuda(), labels.cuda()`\n",
    "- and convert your model to cuda:\n",
    "\n",
    "`model.cuda()`\n",
    "\n",
    "Alternatively, you can specify your GPU as a device:\n",
    "- your first GPU is usually indexed as 0:\n",
    "\n",
    "`device = torch.device('cuda:0')`\n",
    "\n",
    "(when you are debugging your code, it might be better to switch back to CPU: `device = torch.device('cpu')` )\n",
    "- send your variables and model to the device, for example:\n",
    "\n",
    "`inputs = inputs.to(device)`, `labels = labels.to(device)`, `model.to(device)`\n",
    "\n",
    "The following links would be useful: when you want to run your model on a GPU:  \n",
    " - [pytorch doc](http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu)\n",
    " - [mnist pytorch gpu example](https://github.com/pytorch/examples/blob/master/mnist/main.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adding a CRF on top of BiLSTM\n",
    "\n",
    "We will now be building a `CRF` on top of the `BiLSTM` for Part-of-Speech tagging.\n",
    "\n",
    "Recall that the `CRF` computes a conditional probability. Let Y be a tag sequence and X an input sequence of words. Then we compute  \n",
    "\n",
    "$P (Y \\mid X) = \\frac{exp(Score(X,Y))}{\\sum_{Y_i}exp(Score(X,Y_i))}$    \n",
    "where the the score is determined by defining some log potentials $\\log\\Psi(X,Y)$ such that these potential only look at the local features.  \n",
    "\n",
    "In the Bi-LSTM CRF, we define two kinds of potentials: emission and transition. \n",
    "- The emission potential for the word at index $i$ comes from the hidden state of the Bi-LSTM at timestep $i$. \n",
    "- The transition scores are stored in a `|T|x|T|` matrix `transitions`, where T is the tag set. In my implementation, `transitions[j][k]` is the score of transitioning from tag k to tag j.\n",
    "\n",
    "$Score(X,Y) = \\sum_{i}\\log\\Psi_{emit}(y_i \\rightarrow x_i) + \\sum_{i}\\log\\Psi_{trans}(y_{i-1} \\rightarrow y_{i}) \\\\\n",
    " Score(X,Y) = \\sum_{i} h_{i}[y_{i}] + transitions_{y_i,y_{i-1}}$\n",
    " \n",
    "See Eisenstein Ch. 7.5.3 for more details on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since, we are now using a `CRF`, we need to add `START_TAG` and `END_TAG` to the tagset: so, we modify `tag_to_ix` and `ix_to_tag` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding START_TAG and END_TAG to all_tags, updating tag_to_ix\n",
    "if START_TAG not in all_tags:\n",
    "    all_tags.append(START_TAG)\n",
    "if END_TAG not in all_tags:\n",
    "    all_tags.append(END_TAG)\n",
    "all_tags = sorted(all_tags)\n",
    "if START_TAG not in tag_to_ix:\n",
    "    tag_to_ix[START_TAG] = len(tag_to_ix)\n",
    "if END_TAG not in tag_to_ix:\n",
    "    tag_to_ix[END_TAG] = len(tag_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have already provided the transitions parameter to the `bilstm.BiLSTM_CRF` class. Take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2576,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM_CRF(\n",
      "  (word_embeds): Embedding(6900, 30)\n",
      "  (lstm): LSTM(30, 15, bidirectional=True)\n",
      "  (hidden2tag): Linear(in_features=30, out_features=19, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initializing model\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 30\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix), tag_to_ix, embedding_dim, hidden_dim)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe that `BiLSTM_CRF` class is derived from the `BiLSTM` class\n",
    "- Note that we would be using the forward function from `bilstm.BiLSTM` class to obtain the lstm hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us prepare an input sequence\n",
    "sentence = bilstm.prepare_sequence(X_tr[5], word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2566,  0.0795, -0.0240,  0.1035,  0.1465], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "lstm_feats = model.forward(sentence)\n",
    "print (lstm_feats[0][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6.1** (*6 points*) \n",
    "Complete the `bilstm.BiLSTM_CRF.forward_alg()` function to do the following:  \n",
    "This function calculates the log likelihood score for a particular sentence. It works very similar to the `viterbi` algorithm: Instead of finding the maximum `prev_tag`, you need to calculate the probability to arrive at the `curr_tag` for the `curr_token`. The forward algorithm is described in Eisenstein Ch. 7.5.3 (also referred as forward recurrence or sum-product algorithm). In contrast, the Viterbi algorithm is a max-product algorithm.\n",
    "\n",
    "**Reflect**: What's the core difference between a sum-product and max-product algorithm? Why do we need a sum-product algorithm in CRF?\n",
    "\n",
    "- **Inputs**: `feats`, the hidden states for each token in the input_sequence. Consider this to be the emission potential of each token for each tag.\n",
    "    - Make sure to use the `self.transitions` that is defined to capture the tag-transition probabilities\n",
    "- **Outputs**: `alpha`, a pytorch variable containing the scalar score for the entire input, $\\log \\sum_{y_{1:M}} P(w, y)$ \n",
    "- **Tests**: ```test_bilstm_crf.py: test_forward_alg()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2661,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2662,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(711);\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing an input sentence to obtain lstm_feats\n",
    "lstm_feats = model.forward(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = model.forward_alg(lstm_feats)\n",
    "print (alpha.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6.2** (*4 points*)\n",
    "Complete the function `bilstm.BiLSTM_CRF.score_sentence()` to obtain the joint log-likelihood score of the particular sequence of tokens and their tags.\n",
    "- **Inputs**:\n",
    "    - `feats`: the hidden state scores for each token in the input sentence. Consider this to be the emission potential of each token for each tag.\n",
    "    - `gold_tags`: a pytorch Variable of the gold sequence of tags: obtain the joint-log-likelihood score of the sequence with the feats and gold_tags.\n",
    "- **Outputs**:\n",
    "    - a pytorch variable of the score. \n",
    "- **Tests**: ```test_bilstm_crf.py: test_score_sentence()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2588,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2589,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(711);\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare both the tokens and tags to be passed as input\n",
    "sentence = bilstm.prepare_sequence(X_tr[5], word_to_ix)\n",
    "tags = bilstm.prepare_sequence(Y_tr[5], tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2591,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(711);\n",
    "lstm_feats = model.forward(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.8153057]\n"
     ]
    }
   ],
   "source": [
    "score = model.score_sentence(lstm_feats, tags)\n",
    "print (score.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6.3** (*2 points*) Complete the `bilstm.BiLSTM_CRF.predict()` function to decode the tags using the viterbi algorithm. Make sure to use the viterbi functions defined previously.\n",
    "- **Inputs**:\n",
    "    - `sentence`: a pytorch Variable of sequence of ids of the input_tokens\n",
    "- **Outputs**:\n",
    "    - `best_path`: a list of tags for the sequence of tokens\n",
    "- **Tests**: ```test_bilstm_crf.py: test_predict()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2593,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(viterbi);\n",
    "reload(bilstm);\n",
    "torch.manual_seed(711);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2594,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bilstm.BiLSTM_CRF(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 2595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PUNCT', 'ADV', 'SCONJ', 'PUNCT', 'ADV', 'SCONJ', 'PUNCT', 'ADV', 'SCONJ', 'PUNCT', 'ADV', 'SCONJ', 'SYM']\n"
     ]
    }
   ],
   "source": [
    "best_tags = model.predict(sentence)\n",
    "print (best_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUX', 'ADV', 'SCONJ', 'PUNCT', 'ADV', 'SCONJ', 'PUNCT', 'ADV', 'SCONJ', 'PUNCT', 'ADV', 'SCONJ', 'SYM']\n"
     ]
    }
   ],
   "source": [
    "best_tags = model.predict(sentence)\n",
    "print (best_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 6.4** (*2 points*)\n",
    "Complete the `bilstm.BiLSTM_CRF.neg_log_likelihood()` function to obtain the negative log likelihood loss. This function calculates the loss function for the `CRF`. Observe that, this can be easily calculated using the previously defined functions.  \n",
    "You should use the `forward(), forward_alg(), score_sentence()` functions defined previously.\n",
    "\n",
    "- **Tests**: ```test_bilstm_crf.py: test_neg_log_likelihood()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2597,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2598,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(711);\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2599,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_feats = model.forward(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([41.1685], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = model.neg_log_likelihood(lstm_feats, bilstm.prepare_sequence(Y_tr[5], tag_to_ix))\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..F.\n",
      "======================================================================\n",
      "FAIL: test_bilstm_crf.test_predict\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/iws/daksh97/miniconda3/envs/mynlpenv/lib/python3.8/site-packages/nose/case.py\", line 198, in runTest\n",
      "    self.test(*self.arg)\n",
      "  File \"/homes/iws/daksh97/CSE447-sp22-a2-daksh97/tests/test_bilstm_crf.py\", line 67, in test_predict\n",
      "    eq_(best_tags[0:5],['NOUN', 'ADJ', 'CONJ', 'ADV', 'ADJ'])\n",
      "AssertionError: ['ADV', 'ADJ', 'CONJ', 'ADV', 'ADJ'] != ['NOUN', 'ADJ', 'CONJ', 'ADV', 'ADJ']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 1.109s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_bilstm_crf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting all the above components together, let us train the `BiLSTM-CRF` model. **Don't worry about matching the scores for the following code blocks from now. Just Make sure that you pass the unit tests.** \n",
    "- You may want to use pretrained embeddings to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2668,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 30\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix), tag_to_ix, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sending loss function so that we can calculate the loss for the BiLSTM-CRF\n",
    "loss = model.neg_log_likelihood\n",
    "model, losses, accuracies = bilstm.train_model(loss, model, X_tr,Y_tr, word_to_ix, tag_to_ix,\n",
    "                                               X_dv, Y_dv, \n",
    "                                               num_its=5, status_frequency=1,\n",
    "                                               optim_args = {'lr':0.2,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "bilstm.plot_results(losses, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try and Tune the hyperparameters such that you improve the accuracy on the dev set.\n",
    "You can try changing the number of LSTM layers, the hidden dimension units, the FC layer dimensions, using pretrained embeddings etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2459,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 30\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix),tag_to_ix,embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# sending loss function so that we can calculate the loss for the BiLSTM-CRF\n",
    "loss = model.neg_log_likelihood\n",
    "model, losses, accuracies = bilstm.train_model(loss, model, X_tr,Y_tr, word_to_ix, tag_to_ix,\n",
    "                                               X_dv, Y_dv, \n",
    "                                               num_its=10, status_frequency=2,\n",
    "                                               optim_args = {'lr':0.1,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "bilstm.plot_results(losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2462,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tagger_base);\n",
    "reload(bilstm);\n",
    "confusion = tagger_base.eval_model(model,'bilstm_crf-dev-en.preds', word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2464,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_model(model,'bilstm_crf-te-en.preds',word_to_ix, all_tags, testfile=TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8134707903780068\n"
     ]
    }
   ],
   "source": [
    "# you don't have en-ud-test.conllu, so you can't run this\n",
    "te_confusion = scorer.get_confusion(TEST_FILE,'bilstm_crf-te-en.preds')\n",
    "print (scorer.accuracy(te_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging for Norwegian Language.\n",
    "We will use the same `BiLSTM-CRF` part of speech tagger for Norwegian now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running a `BiLSTM-CRF` model on the norwegian language. Make sure your model runs on the norwegian data. \n",
    "- You may want to use the pretrained embeddings for norwegian to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2465,
   "metadata": {},
   "outputs": [],
   "source": [
    "if START_TAG not in all_tags_nr:\n",
    "    all_tags_nr.append(START_TAG)\n",
    "if END_TAG not in all_tags_nr:\n",
    "    all_tags_nr.append(END_TAG)\n",
    "all_tags_nr = sorted(all_tags_nr)\n",
    "if START_TAG not in tag_to_ix_nr:\n",
    "    tag_to_ix_nr[START_TAG]=len(tag_to_ix_nr)\n",
    "if END_TAG not in tag_to_ix_nr:\n",
    "    tag_to_ix_nr[END_TAG]=len(tag_to_ix_nr)\n",
    "# we will be using this tag_to_ix and ix_to_tag from now on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2466,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 30\n",
    "hidden_dim = 30\n",
    "model = bilstm.BiLSTM_CRF(len(word_to_ix_nr), tag_to_ix_nr, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# sending loss function so that we can calculate the loss for the BiLSTM-CRF\n",
    "loss = model.neg_log_likelihood\n",
    "model, losses, accuracies = bilstm.train_model(loss, model, X_tr_nr, Y_tr_nr, word_to_ix_nr, tag_to_ix_nr,\n",
    "                                               X_dv_nr, Y_dv_nr, \n",
    "                                               num_its=10, status_frequency=2,\n",
    "                                               optim_args = {'lr':0.1,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bilstm);\n",
    "bilstm.plot_results(losses, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2469,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tagger_base);\n",
    "reload(bilstm);\n",
    "confusion = tagger_base.eval_model(model,'bilstm_crf-dev-nr.preds', word_to_ix_nr, \n",
    "                                   trainfile=NR_TRAIN_FILE, testfile=NR_DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2471,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_model(model,'bilstm_crf-te-nr.preds',word_to_ix_nr, all_tags_nr, \n",
    "                        trainfile=NR_TRAIN_FILE, testfile=NR_TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8559649574851842\n"
     ]
    }
   ],
   "source": [
    "# you don't have no_bokmaal-ud-test.conllu, so you can't run this\n",
    "te_confusion = scorer.get_confusion(NR_TEST_FILE,'bilstm_crf-te-nr.preds')\n",
    "print (scorer.accuracy(te_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Bakeoff\n",
    "**Note: In this section, you can copy any cells from previous sections of the notebook to the free space below.**\n",
    "\n",
    "**Deliverable 7.1** (*9 points* + *4 points* possible bonus):\n",
    "\n",
    "Try to get the best accuracy possible on both `English` and `Norwegian` tagging. You are expected to get at least `87.00%` on the dev dataset for both English and Norwegian. You can use any model that you have implemented in this assignment: HMM, BiLSTM, or BiLSTM-CRF.\n",
    "- HMM is unlikely to score high enough for full credit.\n",
    "- BiLSTM-CRF is more accurate than BiLSTM in theory, but it takes a long time to train. So iterating on BiLSTM might be better.\n",
    "- Some ideas that might be helpful:\n",
    "    - Better features, such as character-level/morphological features\n",
    "    - Better optimizer\n",
    "    - Number of Layers and Hidden units in the BiLSTM\n",
    "    - More hidden layers in the Fully Connected Layer\n",
    "    - Better loss function, like structured perceptron\n",
    "    - Using Pretrained Embeddings like [fastText](https://github.com/facebookresearch/fastText), [Polyglot](polyglot.readthedocs.io/en/latest/Embeddings.html), [word2vec](https://code.google.com/archive/p/word2vec/), [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "    - Dropout or other regularization scheme\n",
    "- For Norwegian, there are officially [two written forms of language](https://en.wikipedia.org/wiki/Norwegian_language): `Bokmål` and `Nynorsk`. The dataset we are using is for the `Bokmål` language. So, when using pretrained embeddings make sure to use it for that specific form.\n",
    "- If you use dropout during training, consider using `model.eval()` before testing the model to deactivate the dropout layer; the model is in a \"train\" mode (`model.train()`) by default.\n",
    "\n",
    "**Output files:** Make sure to name your files as follows. The unit tests will check for these files.\n",
    "- `bakeoff-dev-en.preds` ( Predictions for the dev dataset of English ) \n",
    "- `bakeoff-te-en.preds`  ( Predictions for the test dataset of English ) \n",
    "- `bakeoff-dev-nr.preds` ( Predictions for the dev dataset of Norwegian ) \n",
    "- `bakeoff-te-nr.preds`  ( Predictions for the test dataset of Norwegian ) \n",
    "\n",
    "**Tests**: `test_bakeoff.py`: \n",
    "- `test_en_dev_accuracy()`\n",
    "- `test_en_test_accuracy()` # you cannot run this unit test.\n",
    "- `test_nr_dev_accuracy()`\n",
    "- `test_nr_test_accuracy()` # you cannot run this unit test.\n",
    "\n",
    "### Rubric\n",
    "\n",
    "Dev Set (**for each language, so multiply by two for total**)\n",
    "- $\\geq$ 85% (*1 points*)\n",
    "- $\\geq$ 86% (*2 points*)\n",
    "- $\\geq$ 87% (*3 points*)\n",
    "\n",
    "Test Set (**for each language, so multiply by two for total**)\n",
    "- $\\geq$ 84% (*0.5 points*)\n",
    "- $\\geq$ 85% (*1 points*)\n",
    "- $\\geq$ 86% (*1.5 points*)\n",
    "- Top five in the class (*2 points* bonus)\n",
    "- We'll also give 2 bonus points to particularly unique / creative / well-motivated solutions (with motivation to be included in the write-up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2978,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free space\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return to_scalar(idx)\n",
    "def to_scalar(var):\n",
    "    # returns a python float\n",
    "    return var.view(-1).data.tolist()\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] if w in to_ix else to_ix[UNK] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, hidden_layers, embeddings=None):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        self.word_embeds = nn.Embedding(self.vocab_size, self.embedding_dim) \n",
    "        \n",
    "        if embeddings is not None:\n",
    "            self.word_embeds.weight.data.copy_(torch.from_numpy(embeddings))\n",
    "            \n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim//2, num_layers=self.hidden_layers, bidirectional = True)\n",
    "        self.lin1 = nn.Linear(self.hidden_dim, 30)\n",
    "        self.lin2 = nn.Linear(30,20)\n",
    "        self.ac = nn.LeakyReLU()\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.hidden2tag = nn.Linear(self.hidden_dim, self.tagset_size)\n",
    "        \n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # axes semantics are: bidirectinal*num_of_layers, minibatch_size, hidden_dimension; we use noisy initialization\n",
    "        \n",
    "        return (Variable(torch.randn(2*self.hidden_layers, 1, self.hidden_dim // 2)),\n",
    "                Variable(torch.randn(2*self.hidden_layers, 1, self.hidden_dim // 2)))\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "        x = self.word_embeds(sentence)\n",
    "        x, (hn,cn) = self.lstm(x.view([len(sentence),1,self.embedding_dim]), (self.hidden))\n",
    "        #x = self.lin1(x)\n",
    "        #x = self.lin2(x)\n",
    "        #x = self.drop(x)\n",
    "        #x = self.ac(x)\n",
    "        return self.hidden2tag(x).reshape((len(sentence),  self.tagset_size))\n",
    "               \n",
    "    \n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        lstm_feats = self.forward(sentence)\n",
    "        softmax_layer = torch.nn.Softmax(dim=1)\n",
    "        probs = softmax_layer(lstm_feats)\n",
    "        idx = argmax(probs)\n",
    "        tags = [self.ix_to_tag[ix] for ix in idx]\n",
    "        return tags\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2989,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def train_model(loss, model, X_tr,Y_tr, word_to_ix, tag_to_ix, X_dv=None, Y_dv = None, num_its=50, status_frequency=10,\n",
    "               optim_args = {'lr':0.1,'momentum':0},\n",
    "               param_file = 'best.params'):\n",
    "    \n",
    "    #initialize optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), **optim_args)\n",
    "    \n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    \n",
    "    for epoch in range(num_its):\n",
    "        \n",
    "        loss_value=0\n",
    "        count1=0\n",
    "        \n",
    "        for X,Y in zip(X_tr,Y_tr):\n",
    "            X_tr_var = prepare_sequence(X, word_to_ix)\n",
    "            Y_tr_var = prepare_sequence(Y, tag_to_ix)\n",
    "            \n",
    "            # set gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            lstm_feats= model.forward(X_tr_var)\n",
    "            \n",
    "            for i in range(1,lstm_feats.size()[0]):\n",
    "                if X[i][0].isupper():\n",
    "                    lstm_feats[i][tag_to_ix['NOUN']] == 1.0\n",
    "                \n",
    "            output = loss(lstm_feats,Y_tr_var)\n",
    "            \n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            loss_value += output.item()\n",
    "            count1+=1\n",
    "            \n",
    "            \n",
    "        losses.append(loss_value/count1)\n",
    "        \n",
    "        # write parameters if this is the best epoch yet\n",
    "        acc=0        \n",
    "        if X_dv is not None and Y_dv is not None:\n",
    "            acc=0\n",
    "            count2=0\n",
    "            for Xdv, Ydv in zip(X_dv, Y_dv):\n",
    "                \n",
    "                X_dv_var = prepare_sequence(Xdv, word_to_ix)\n",
    "                Y_dv_var = prepare_sequence(Ydv, tag_to_ix)\n",
    "                # run forward on dev data\n",
    "                Y_hat = model.predict(X_dv_var)\n",
    "                \n",
    "                Yhat = np.array([tag_to_ix[yhat] for yhat in Y_hat])\n",
    "                Ydv = np.array([tag_to_ix[ydv] for ydv in Ydv])\n",
    "                \n",
    "                # compute dev accuracy\n",
    "                acc += (evaluation.acc(Yhat,Ydv))*len(Xdv)\n",
    "                count2 += len(Xdv)\n",
    "                # save\n",
    "            acc/=count2\n",
    "            if len(accuracies) == 0 or acc > max(accuracies):\n",
    "                state = {'state_dict':model.state_dict(),\n",
    "                         'epoch':len(accuracies)+1,\n",
    "                         'accuracy':acc}\n",
    "                torch.save(state,param_file)\n",
    "            accuracies.append(acc)\n",
    "        # print status message if desired\n",
    "        if status_frequency > 0 and epoch % status_frequency == 0:\n",
    "            print(\"Epoch \"+str(epoch+1)+\": Dev Accuracy: \"+str(acc))\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6900, 64)\n",
      "Epoch 1: Dev Accuracy: 0.7689468828258864\n",
      "Epoch 2: Dev Accuracy: 0.8040068538289179\n",
      "Epoch 3: Dev Accuracy: 0.8237775141689733\n",
      "Epoch 4: Dev Accuracy: 0.8372215632002109\n",
      "Epoch 5: Dev Accuracy: 0.8356399103730064\n",
      "Epoch 6: Dev Accuracy: 0.8518518518518519\n",
      "Epoch 7: Dev Accuracy: 0.8629234216422829\n",
      "Epoch 8: Dev Accuracy: 0.8609463556082774\n",
      "Epoch 9: Dev Accuracy: 0.8457888493475683\n",
      "Epoch 10: Dev Accuracy: 0.8606827468037432\n",
      "Epoch 11: Dev Accuracy: 0.8552787663107948\n",
      "Epoch 12: Dev Accuracy: 0.8580466587584026\n",
      "Epoch 13: Dev Accuracy: 0.8577830499538684\n",
      "Epoch 14: Dev Accuracy: 0.8629234216422829\n",
      "Epoch 15: Dev Accuracy: 0.8577830499538684\n",
      "Epoch 16: Dev Accuracy: 0.8565968103334651\n",
      "Epoch 17: Dev Accuracy: 0.8627916172400159\n",
      "Epoch 18: Dev Accuracy: 0.8579148543561355\n",
      "Epoch 19: Dev Accuracy: 0.8605509424014762\n",
      "CPU times: user 14min 45s, sys: 1.76 s, total: 14min 46s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'data/polyglot-en.pkl'\n",
    "word_embeddings = bilstm.obtain_polyglot_embeddings(filename, word_to_ix)\n",
    "print(word_embeddings.shape)\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 64\n",
    "hidden_dim = 30\n",
    "hidden_layers = 1\n",
    "model = BiLSTM(len(word_to_ix), tag_to_ix, embedding_dim, hidden_dim, hidden_layers, word_embeddings)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model, losses, accuracies = train_model(loss, model, X_tr,Y_tr, word_to_ix, tag_to_ix,\n",
    "                                               X_dv, Y_dv, \n",
    "                                               num_its=19, status_frequency=1,\n",
    "                                               optim_args = {'lr':0.09,'momentum':0.0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2998,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8616053776196125\n"
     ]
    }
   ],
   "source": [
    "confusion = tagger_base.eval_model(model,'bakeoff-dev-en.preds', word_to_ix, \n",
    "                                   trainfile=TRAIN_FILE, testfile=DEV_FILE)\n",
    "print (scorer.accuracy(confusion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2999,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_model(model,'bakeoff-te-en.preds',word_to_ix, all_tags, \n",
    "                        trainfile=TRAIN_FILE, testfile=TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 64) 7600\n",
      "Epoch 1: Dev Accuracy: 0.23522662076878945\n",
      "Epoch 2: Dev Accuracy: 0.5997705106138841\n",
      "Epoch 3: Dev Accuracy: 0.7919678714859437\n",
      "Epoch 4: Dev Accuracy: 0.8302925989672978\n",
      "Epoch 5: Dev Accuracy: 0.8478485370051635\n",
      "Epoch 6: Dev Accuracy: 0.8613884107860011\n",
      "Epoch 7: Dev Accuracy: 0.8052782558806655\n",
      "Epoch 8: Dev Accuracy: 0.861732644865175\n",
      "Epoch 9: Dev Accuracy: 0.8706827309236947\n",
      "Epoch 10: Dev Accuracy: 0.8749282845668388\n",
      "Epoch 11: Dev Accuracy: 0.8784853700516351\n",
      "Epoch 12: Dev Accuracy: 0.8799770510613885\n",
      "Epoch 13: Dev Accuracy: 0.88100975329891\n",
      "Epoch 14: Dev Accuracy: 0.8845668387837062\n",
      "Epoch 15: Dev Accuracy: 0.8861732644865175\n",
      "Epoch 16: Dev Accuracy: 0.8869764773379232\n",
      "Epoch 17: Dev Accuracy: 0.8859437751004016\n",
      "Epoch 18: Dev Accuracy: 0.8868617326448652\n",
      "Epoch 19: Dev Accuracy: 0.8869764773379232\n",
      "Epoch 20: Dev Accuracy: 0.8864027538726333\n",
      "CPU times: user 22min 5s, sys: 2 s, total: 22min 7s\n",
      "Wall time: 12min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename_nr = 'data/polyglot-no.pkl'\n",
    "word_embeddings_nr = bilstm.obtain_polyglot_embeddings(filename_nr, word_to_ix_nr)\n",
    "print(word_embeddings_nr.shape, len(word_to_ix_nr))\n",
    "torch.manual_seed(711);\n",
    "embedding_dim = 64\n",
    "hidden_dim = 30\n",
    "hidden_layers = 3\n",
    "model2 = BiLSTM(len(word_to_ix_nr), tag_to_ix_nr, embedding_dim, hidden_dim, hidden_layers, word_embeddings_nr)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model2, losses, accuracies = bilstm.train_model(loss, model2, X_tr_nr,Y_tr_nr, word_to_ix_nr, tag_to_ix_nr,\n",
    "                                               X_dv_nr, Y_dv_nr, \n",
    "                                               num_its=20, status_frequency=1,\n",
    "                                               optim_args = {'lr':0.09,'momentum':0}, param_file = 'best.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3002,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8847963281698221\n"
     ]
    }
   ],
   "source": [
    "confusion = tagger_base.eval_model(model2,'bakeoff-dev-nr.preds', word_to_ix_nr, \n",
    "                                   trainfile=NR_TRAIN_FILE, testfile=NR_DEV_FILE)\n",
    "print (scorer.accuracy(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3003,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_base.apply_model(model,'bakeoff-te-nr.preds',word_to_ix, all_tags, \n",
    "                        trainfile=TRAIN_FILE, testfile=TEST_FILE_HIDDEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Writeup\n",
    "\n",
    "Total: 6 points\n",
    "\n",
    "You can start your write-up in any format you prefer (e.g., LaTeX, Markdown, handwritten if intelligible), but please remember to export to `writeup.pdf` upon submission. You will be encouraged to post or discuss your writeup on Ed *after the due date (plus late days)*.\n",
    "\n",
    "**Deliverable 3.1** (placeholder for your finished Viterbi table in Section 3)\n",
    "\n",
    "**Deliverable 8.1** (4 points):\n",
    "\n",
    "Briefly describe your bakeoff design.\n",
    "\n",
    "**Deliverable 8.2** (2 points):\n",
    "\n",
    "When did you start this assignment and how much time did you spend overall? On a scale of 1 to 5, how hard do you think is this assignment and how much do you think you learned from it? You will get a full score for this question unless you leave it blank.\n",
    "\n",
    "**Reflection 8.3** (0 points):\n",
    "\n",
    "At the beginning of this notebook, we load in some labeled training data and use them in all of the methods. However, obtaining the labels (e.g., POS tags) for each data instance might be expensive, especially for some low-resource languages. Is it possible to design a method that does *sequence labeling* without training *labels*? (We still have the training *sequences*, otherwise we essentially have nothing.)\n",
    "\n",
    "Hint: a general method called expectation-maximization (EM) can be relevant in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
